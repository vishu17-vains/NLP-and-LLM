{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu839UXaFqE7QsBQKj2N8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishu17-vains/NLP-and-LLM/blob/main/TEXT_SUMMARIZATION_USING_SPACY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC9v3Y2FKy-W",
        "outputId": "54ec728a-ea4a-4e9a-9474-6e462d62d058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCrzhpOELqEk",
        "outputId": "c312e114-0f84-4c16-f990-0502d6ba250c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# loading the english kanguage model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# example text\n",
        "text = \"Apple is a delicious food and healthy\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# print named entities found in the text\n",
        "print(\"NamedEntities, Phrases, and Concepts:\")\n",
        "for ent in doc.ents:\n",
        "  print(f\"{ent.text:15} {ent.label}{ent.label_:10}{ent.start_char:10}{ent.end_char:10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93NxTJHfMnKZ",
        "outputId": "2f58cdf2-c7f2-4ace-de57-d9757f129883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NamedEntities, Phrases, and Concepts:\n",
            "Apple           383ORG                0         5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"data science and ai has greate career ahead\")"
      ],
      "metadata": {
        "id": "6KnWaVzXRlTp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyQt5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_MO3sX5-H9H",
        "outputId": "0cf07f7e-a7ff-4de5-e856-0ca9009b8a37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyQt5\n",
            "  Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting PyQt5-sip<13,>=12.15 (from PyQt5)\n",
            "  Downloading PyQt5_sip-12.16.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (421 bytes)\n",
            "Collecting PyQt5-Qt5<5.16.0,>=5.15.2 (from PyQt5)\n",
            "  Downloading PyQt5_Qt5-5.15.16-py3-none-manylinux2014_x86_64.whl.metadata (536 bytes)\n",
            "Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyQt5_Qt5-5.15.16-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyQt5_sip-12.16.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl (270 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.8/270.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyQt5-Qt5, PyQt5-sip, PyQt5\n",
            "Successfully installed PyQt5-5.15.11 PyQt5-Qt5-5.15.16 PyQt5-sip-12.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyQt5"
      ],
      "metadata": {
        "id": "UHYzB38A-iYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXsRqPEY-iiz",
        "outputId": "41d5ff5b-ce25-47c6-eae0-153a7a800533"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "data science and ai has greate career ahead"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoAo6cBd-pfp",
        "outputId": "477b9b2c-f1fd-4ae3-b812-3cab46d3fc4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "science\n",
            "and\n",
            "ai\n",
            "has\n",
            "greate\n",
            "career\n",
            "ahead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5odeKcCo-pkj",
        "outputId": "2562fd1e-8d42-486d-a1e8-6ddae195e593"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
            "is be AUX VBZ aux xx True True\n",
            "looking look VERB VBG ROOT xxxx True False\n",
            "at at ADP IN prep xx True True\n",
            "buying buy VERB VBG pcomp xxxx True False\n",
            "U.K. U.K. PROPN NNP dobj X.X. False False\n",
            "startup startup NOUN NN dep xxxx True False\n",
            "for for ADP IN prep xxx True True\n",
            "$ $ SYM $ quantmod $ False False\n",
            "1 1 NUM CD compound d False False\n",
            "billion billion NUM CD pobj xxxx True False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K1yfMZW-pvx",
        "outputId": "ff273e34-c3a8-4c77-9c01-4cfc15c8169a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROPN\n",
            "AUX\n",
            "VERB\n",
            "ADP\n",
            "VERB\n",
            "PROPN\n",
            "NOUN\n",
            "ADP\n",
            "SYM\n",
            "NUM\n",
            "NUM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvXSFmW0-5hL",
        "outputId": "5d6fa216-d9af-4fb6-a57d-895884d84cf6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple PROPN\n",
            "is AUX\n",
            "looking VERB\n",
            "at ADP\n",
            "buying VERB\n",
            "U.K. PROPN\n",
            "startup NOUN\n",
            "for ADP\n",
            "$ SYM\n",
            "1 NUM\n",
            "billion NUM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxSXRHWP-7me",
        "outputId": "d8a00a3c-3761-461a-feb4-35631a358ae0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple PROPN Apple\n",
            "is AUX be\n",
            "looking VERB look\n",
            "at ADP at\n",
            "buying VERB buy\n",
            "U.K. PROPN U.K.\n",
            "startup NOUN startup\n",
            "for ADP for\n",
            "$ SYM $\n",
            "1 NUM 1\n",
            "billion NUM billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
        "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
        "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured \"\"\""
      ],
      "metadata": {
        "id": "mP-M0X2m-5nH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "LSHlDZm6_I0B",
        "outputId": "97f90702-be42-47fb-b888-362f5a958661"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation"
      ],
      "metadata": {
        "id": "xfq0J_xx_Kd8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = list(STOP_WORDS)\n",
        "stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKCJIFCm_KiX",
        "outputId": "aac9429f-8167-423c-b538-2f0797c8c079"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['these',\n",
              " 'side',\n",
              " 'can',\n",
              " 'whom',\n",
              " 'in',\n",
              " 'make',\n",
              " 'into',\n",
              " 'after',\n",
              " 'around',\n",
              " 'might',\n",
              " 'herself',\n",
              " 'cannot',\n",
              " 'upon',\n",
              " 'many',\n",
              " 'always',\n",
              " 'toward',\n",
              " 'though',\n",
              " 'wherever',\n",
              " 'am',\n",
              " \"'ll\",\n",
              " 'his',\n",
              " 'indeed',\n",
              " 'nine',\n",
              " 'ours',\n",
              " 'hereby',\n",
              " 'below',\n",
              " 'towards',\n",
              " 'move',\n",
              " 'call',\n",
              " 'hundred',\n",
              " 'about',\n",
              " 'thence',\n",
              " 'thus',\n",
              " 'under',\n",
              " 'anyway',\n",
              " 'somewhere',\n",
              " 'ca',\n",
              " 'seemed',\n",
              " 'all',\n",
              " 'you',\n",
              " 'not',\n",
              " 'while',\n",
              " 'much',\n",
              " 'everyone',\n",
              " 'so',\n",
              " 'either',\n",
              " 'otherwise',\n",
              " 'n’t',\n",
              " 'regarding',\n",
              " 'by',\n",
              " 'eleven',\n",
              " 'however',\n",
              " 'anyhow',\n",
              " 'such',\n",
              " 'nor',\n",
              " 'more',\n",
              " 'along',\n",
              " 'before',\n",
              " 'becoming',\n",
              " 'been',\n",
              " 'top',\n",
              " 'he',\n",
              " 'empty',\n",
              " 'them',\n",
              " 'therefore',\n",
              " 'above',\n",
              " 'whose',\n",
              " 'wherein',\n",
              " 'whenever',\n",
              " 'through',\n",
              " 'be',\n",
              " 'whence',\n",
              " 'seems',\n",
              " 'became',\n",
              " 'i',\n",
              " 'become',\n",
              " 'except',\n",
              " 'full',\n",
              " \"'ve\",\n",
              " 'mostly',\n",
              " 'others',\n",
              " 'onto',\n",
              " 'is',\n",
              " 'whereafter',\n",
              " 'sixty',\n",
              " 'whereupon',\n",
              " 'did',\n",
              " 'were',\n",
              " 'whereas',\n",
              " 'across',\n",
              " 'never',\n",
              " 'has',\n",
              " 'whereby',\n",
              " 'else',\n",
              " 'third',\n",
              " 'me',\n",
              " 'may',\n",
              " \"n't\",\n",
              " \"'m\",\n",
              " 'afterwards',\n",
              " 'at',\n",
              " 'although',\n",
              " 'here',\n",
              " 'nothing',\n",
              " 'hence',\n",
              " 'neither',\n",
              " 'those',\n",
              " 'us',\n",
              " 'whether',\n",
              " 'also',\n",
              " 'six',\n",
              " 'our',\n",
              " 'own',\n",
              " 'whole',\n",
              " 'between',\n",
              " 'quite',\n",
              " 'her',\n",
              " 'now',\n",
              " 'due',\n",
              " 'their',\n",
              " 'where',\n",
              " 'thereupon',\n",
              " 'one',\n",
              " 'the',\n",
              " '’re',\n",
              " 'yourself',\n",
              " 'really',\n",
              " 'as',\n",
              " 'everywhere',\n",
              " 'since',\n",
              " 'four',\n",
              " 'should',\n",
              " 'unless',\n",
              " 'down',\n",
              " 'hers',\n",
              " 'latterly',\n",
              " 'well',\n",
              " 'rather',\n",
              " 'noone',\n",
              " 'there',\n",
              " 'only',\n",
              " 'back',\n",
              " 'forty',\n",
              " 'done',\n",
              " 'ten',\n",
              " 'becomes',\n",
              " 'itself',\n",
              " 'thru',\n",
              " 'if',\n",
              " 'keep',\n",
              " 'each',\n",
              " 'my',\n",
              " 'him',\n",
              " 'once',\n",
              " 'everything',\n",
              " 'out',\n",
              " 'among',\n",
              " 'bottom',\n",
              " 'beside',\n",
              " 'take',\n",
              " 'therein',\n",
              " 'will',\n",
              " 'front',\n",
              " 'whatever',\n",
              " 'but',\n",
              " 'again',\n",
              " 'most',\n",
              " 'that',\n",
              " '’m',\n",
              " 'very',\n",
              " 'see',\n",
              " 'its',\n",
              " '’ll',\n",
              " 'something',\n",
              " 'ourselves',\n",
              " 'too',\n",
              " 'she',\n",
              " 'two',\n",
              " 'hereupon',\n",
              " 'n‘t',\n",
              " 'yourselves',\n",
              " 'nobody',\n",
              " 'have',\n",
              " 'latter',\n",
              " 'seeming',\n",
              " 'yours',\n",
              " 'on',\n",
              " 'another',\n",
              " 'few',\n",
              " 'twenty',\n",
              " 'eight',\n",
              " 'himself',\n",
              " '‘re',\n",
              " 'get',\n",
              " 'next',\n",
              " 'moreover',\n",
              " 'are',\n",
              " 'being',\n",
              " 'namely',\n",
              " 'does',\n",
              " 'beyond',\n",
              " 'what',\n",
              " 'amongst',\n",
              " 'nevertheless',\n",
              " 'who',\n",
              " 'five',\n",
              " '‘ll',\n",
              " 'over',\n",
              " 'name',\n",
              " 'whoever',\n",
              " 'often',\n",
              " \"'d\",\n",
              " 'yet',\n",
              " 'someone',\n",
              " 'part',\n",
              " 'had',\n",
              " 'an',\n",
              " '’s',\n",
              " 'of',\n",
              " 'myself',\n",
              " 'nowhere',\n",
              " 'say',\n",
              " 'perhaps',\n",
              " 'off',\n",
              " 'put',\n",
              " '‘ve',\n",
              " 'herein',\n",
              " 'show',\n",
              " 'any',\n",
              " 'made',\n",
              " 'up',\n",
              " 'twelve',\n",
              " 'then',\n",
              " 'whither',\n",
              " 'formerly',\n",
              " 'besides',\n",
              " \"'s\",\n",
              " 'please',\n",
              " 'sometime',\n",
              " 're',\n",
              " 'behind',\n",
              " 'anything',\n",
              " 'together',\n",
              " 'serious',\n",
              " 'because',\n",
              " 'beforehand',\n",
              " 'somehow',\n",
              " 'some',\n",
              " 'with',\n",
              " 'three',\n",
              " '‘d',\n",
              " 'or',\n",
              " 'mine',\n",
              " 'do',\n",
              " 'anywhere',\n",
              " 'was',\n",
              " 'your',\n",
              " 'per',\n",
              " 'alone',\n",
              " 'amount',\n",
              " 'enough',\n",
              " 'could',\n",
              " 'than',\n",
              " 'former',\n",
              " 'hereafter',\n",
              " '’ve',\n",
              " 'which',\n",
              " 'every',\n",
              " 'must',\n",
              " 'they',\n",
              " 'other',\n",
              " \"'re\",\n",
              " 'this',\n",
              " 'when',\n",
              " 'just',\n",
              " 'doing',\n",
              " 'and',\n",
              " 'give',\n",
              " 'thereafter',\n",
              " 'during',\n",
              " 'even',\n",
              " 'same',\n",
              " 'via',\n",
              " 'why',\n",
              " 'thereby',\n",
              " 'themselves',\n",
              " 'last',\n",
              " 'used',\n",
              " 'sometimes',\n",
              " 'several',\n",
              " 'a',\n",
              " 'until',\n",
              " 'elsewhere',\n",
              " '‘m',\n",
              " 'fifteen',\n",
              " 'meanwhile',\n",
              " 'almost',\n",
              " 'fifty',\n",
              " 'less',\n",
              " 'still',\n",
              " 'would',\n",
              " 'without',\n",
              " 'go',\n",
              " 'first',\n",
              " 'within',\n",
              " '‘s',\n",
              " 'against',\n",
              " 'throughout',\n",
              " 'for',\n",
              " 'no',\n",
              " '’d',\n",
              " 'we',\n",
              " 'anyone',\n",
              " 'seem',\n",
              " 'none',\n",
              " 'already',\n",
              " 'from',\n",
              " 'using',\n",
              " 'various',\n",
              " 'least',\n",
              " 'how',\n",
              " 'both',\n",
              " 'ever',\n",
              " 'further',\n",
              " 'it',\n",
              " 'to']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MIHCAhT_I5m",
        "outputId": "f81b97fc-fa58-4729-eb1d-b7d3c6ba1b5f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "RR1Q70nG_Wsp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "UArokTSE_arr",
        "outputId": "77e5e4a8-6797-4d50-d879-b08987e84482"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WFOcSKj_a4Y",
        "outputId": "8d62ff01-38e0-476a-950b-1292a1fdbbf0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
              "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
              "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting text from tokens\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hot6sOI2_W35",
        "outputId": "f7973d06-4ad7-49c1-b063-d1874c278740"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'program', 'focuses', 'on', '.', 'The', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaining', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', 'collection', '(', 'whether', 'documents', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'etc', '.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', 'summarization', ',', 'sometimes', 'called', 'query', '-', 'based', 'summarization', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'a', 'query', '.', 'Summarization', 'systems', 'are', 'able', 'to', 'create', 'both', 'query', 'relevant', 'text', 'summaries', 'and', 'generic', 'machine', '-', 'generated', 'summaries', 'depending', 'on', 'what', 'the', 'user', 'needs', '.', '\\n', 'An', 'example', 'of', 'a', 'summarization', 'problem', 'is', 'document', 'summarization', ',', 'which', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', 'others', 'can', 'use', 'multiple', 'source', 'documents', '(', 'for', 'example', ',', 'a', 'cluster', 'of', 'articles', 'on', 'the', 'same', 'topic', ')', '.', 'This', 'problem', 'is', 'called', 'multi', '-', 'document', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represents', 'the', 'latest', 'news', 'as', 'a', 'summary', '.', '\\n', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', 'representative', 'set', 'of', 'images', 'from', 'a', 'larger', 'set', 'of', 'images.[4', ']', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', 'representative', 'images', 'of', 'results', 'in', 'an', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', 'where', 'the', 'system', 'automatically', 'creates', 'a', 'trailer', 'of', 'a', 'long', 'video', '.', 'This', 'also', 'has', 'applications', 'in', 'consumer', 'or', 'personal', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarly', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', 'want', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captured']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1V4QPPB_qa6",
        "outputId": "9bf0f3c7-e8c3-4c61-d982-0ed5976787bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['There',\n",
              " 'are',\n",
              " 'broadly',\n",
              " 'two',\n",
              " 'types',\n",
              " 'of',\n",
              " 'extractive',\n",
              " 'summarization',\n",
              " 'tasks',\n",
              " 'depending',\n",
              " 'on',\n",
              " 'what',\n",
              " 'the',\n",
              " 'summarization',\n",
              " 'program',\n",
              " 'focuses',\n",
              " 'on',\n",
              " '.',\n",
              " 'The',\n",
              " 'first',\n",
              " 'is',\n",
              " 'generic',\n",
              " 'summarization',\n",
              " ',',\n",
              " 'which',\n",
              " 'focuses',\n",
              " 'on',\n",
              " 'obtaining',\n",
              " 'a',\n",
              " 'generic',\n",
              " 'summary',\n",
              " 'or',\n",
              " 'abstract',\n",
              " 'of',\n",
              " 'the',\n",
              " 'collection',\n",
              " '(',\n",
              " 'whether',\n",
              " 'documents',\n",
              " ',',\n",
              " 'or',\n",
              " 'sets',\n",
              " 'of',\n",
              " 'images',\n",
              " ',',\n",
              " 'or',\n",
              " 'videos',\n",
              " ',',\n",
              " 'news',\n",
              " 'stories',\n",
              " 'etc',\n",
              " '.',\n",
              " ')',\n",
              " '.',\n",
              " 'The',\n",
              " 'second',\n",
              " 'is',\n",
              " 'query',\n",
              " 'relevant',\n",
              " 'summarization',\n",
              " ',',\n",
              " 'sometimes',\n",
              " 'called',\n",
              " 'query',\n",
              " '-',\n",
              " 'based',\n",
              " 'summarization',\n",
              " ',',\n",
              " 'which',\n",
              " 'summarizes',\n",
              " 'objects',\n",
              " 'specific',\n",
              " 'to',\n",
              " 'a',\n",
              " 'query',\n",
              " '.',\n",
              " 'Summarization',\n",
              " 'systems',\n",
              " 'are',\n",
              " 'able',\n",
              " 'to',\n",
              " 'create',\n",
              " 'both',\n",
              " 'query',\n",
              " 'relevant',\n",
              " 'text',\n",
              " 'summaries',\n",
              " 'and',\n",
              " 'generic',\n",
              " 'machine',\n",
              " '-',\n",
              " 'generated',\n",
              " 'summaries',\n",
              " 'depending',\n",
              " 'on',\n",
              " 'what',\n",
              " 'the',\n",
              " 'user',\n",
              " 'needs',\n",
              " '.',\n",
              " '\\n',\n",
              " 'An',\n",
              " 'example',\n",
              " 'of',\n",
              " 'a',\n",
              " 'summarization',\n",
              " 'problem',\n",
              " 'is',\n",
              " 'document',\n",
              " 'summarization',\n",
              " ',',\n",
              " 'which',\n",
              " 'attempts',\n",
              " 'to',\n",
              " 'automatically',\n",
              " 'produce',\n",
              " 'an',\n",
              " 'abstract',\n",
              " 'from',\n",
              " 'a',\n",
              " 'given',\n",
              " 'document',\n",
              " '.',\n",
              " 'Sometimes',\n",
              " 'one',\n",
              " 'might',\n",
              " 'be',\n",
              " 'interested',\n",
              " 'in',\n",
              " 'generating',\n",
              " 'a',\n",
              " 'summary',\n",
              " 'from',\n",
              " 'a',\n",
              " 'single',\n",
              " 'source',\n",
              " 'document',\n",
              " ',',\n",
              " 'while',\n",
              " 'others',\n",
              " 'can',\n",
              " 'use',\n",
              " 'multiple',\n",
              " 'source',\n",
              " 'documents',\n",
              " '(',\n",
              " 'for',\n",
              " 'example',\n",
              " ',',\n",
              " 'a',\n",
              " 'cluster',\n",
              " 'of',\n",
              " 'articles',\n",
              " 'on',\n",
              " 'the',\n",
              " 'same',\n",
              " 'topic',\n",
              " ')',\n",
              " '.',\n",
              " 'This',\n",
              " 'problem',\n",
              " 'is',\n",
              " 'called',\n",
              " 'multi',\n",
              " '-',\n",
              " 'document',\n",
              " 'summarization',\n",
              " '.',\n",
              " 'A',\n",
              " 'related',\n",
              " 'application',\n",
              " 'is',\n",
              " 'summarizing',\n",
              " 'news',\n",
              " 'articles',\n",
              " '.',\n",
              " 'Imagine',\n",
              " 'a',\n",
              " 'system',\n",
              " ',',\n",
              " 'which',\n",
              " 'automatically',\n",
              " 'pulls',\n",
              " 'together',\n",
              " 'news',\n",
              " 'articles',\n",
              " 'on',\n",
              " 'a',\n",
              " 'given',\n",
              " 'topic',\n",
              " '(',\n",
              " 'from',\n",
              " 'the',\n",
              " 'web',\n",
              " ')',\n",
              " ',',\n",
              " 'and',\n",
              " 'concisely',\n",
              " 'represents',\n",
              " 'the',\n",
              " 'latest',\n",
              " 'news',\n",
              " 'as',\n",
              " 'a',\n",
              " 'summary',\n",
              " '.',\n",
              " '\\n',\n",
              " 'Image',\n",
              " 'collection',\n",
              " 'summarization',\n",
              " 'is',\n",
              " 'another',\n",
              " 'application',\n",
              " 'example',\n",
              " 'of',\n",
              " 'automatic',\n",
              " 'summarization',\n",
              " '.',\n",
              " 'It',\n",
              " 'consists',\n",
              " 'in',\n",
              " 'selecting',\n",
              " 'a',\n",
              " 'representative',\n",
              " 'set',\n",
              " 'of',\n",
              " 'images',\n",
              " 'from',\n",
              " 'a',\n",
              " 'larger',\n",
              " 'set',\n",
              " 'of',\n",
              " 'images.[4',\n",
              " ']',\n",
              " 'A',\n",
              " 'summary',\n",
              " 'in',\n",
              " 'this',\n",
              " 'context',\n",
              " 'is',\n",
              " 'useful',\n",
              " 'to',\n",
              " 'show',\n",
              " 'the',\n",
              " 'most',\n",
              " 'representative',\n",
              " 'images',\n",
              " 'of',\n",
              " 'results',\n",
              " 'in',\n",
              " 'an',\n",
              " 'image',\n",
              " 'collection',\n",
              " 'exploration',\n",
              " 'system',\n",
              " '.',\n",
              " 'Video',\n",
              " 'summarization',\n",
              " 'is',\n",
              " 'a',\n",
              " 'related',\n",
              " 'domain',\n",
              " ',',\n",
              " 'where',\n",
              " 'the',\n",
              " 'system',\n",
              " 'automatically',\n",
              " 'creates',\n",
              " 'a',\n",
              " 'trailer',\n",
              " 'of',\n",
              " 'a',\n",
              " 'long',\n",
              " 'video',\n",
              " '.',\n",
              " 'This',\n",
              " 'also',\n",
              " 'has',\n",
              " 'applications',\n",
              " 'in',\n",
              " 'consumer',\n",
              " 'or',\n",
              " 'personal',\n",
              " 'videos',\n",
              " ',',\n",
              " 'where',\n",
              " 'one',\n",
              " 'might',\n",
              " 'want',\n",
              " 'to',\n",
              " 'skip',\n",
              " 'the',\n",
              " 'boring',\n",
              " 'or',\n",
              " 'repetitive',\n",
              " 'actions',\n",
              " '.',\n",
              " 'Similarly',\n",
              " ',',\n",
              " 'in',\n",
              " 'surveillance',\n",
              " 'videos',\n",
              " ',',\n",
              " 'one',\n",
              " 'would',\n",
              " 'want',\n",
              " 'to',\n",
              " 'extract',\n",
              " 'important',\n",
              " 'and',\n",
              " 'suspicious',\n",
              " 'activity',\n",
              " ',',\n",
              " 'while',\n",
              " 'ignoring',\n",
              " 'all',\n",
              " 'the',\n",
              " 'boring',\n",
              " 'and',\n",
              " 'redundant',\n",
              " 'frames',\n",
              " 'captured']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3QGSewf_riz",
        "outputId": "11f74cc6-baf0-4160-9299-ac0cc7e4e671"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "322"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vr71230m_vJ9",
        "outputId": "c03c5ad5-ffd3-4dfb-e016-3d6f55f16831"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6TedFtJ_vUu",
        "outputId": "44a167b6-0316-448e-da9f-2d1b476ea447"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
              "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
              "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is neccesarry to  calcualte the freaquency of each and every word, how many time word is repeated in text\n",
        "\n",
        "word_frequencies = {}\n",
        "\n",
        "for word in doc:\n",
        "    if word.text.lower() not in stopwords:\n",
        "        if word.text.lower() not in punctuation:\n",
        "            if word.text not in word_frequencies.keys():\n",
        "                word_frequencies[word.text] = 1\n",
        "            else:\n",
        "                word_frequencies[word.text] += 1"
      ],
      "metadata": {
        "id": "ryl3ce0A_ruz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjCua8zy_qg_",
        "outputId": "fe070a33-a33d-4bbf-da65-96e2a85ffb9f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'broadly': 1,\n",
              " 'types': 1,\n",
              " 'extractive': 1,\n",
              " 'summarization': 11,\n",
              " 'tasks': 1,\n",
              " 'depending': 2,\n",
              " 'program': 1,\n",
              " 'focuses': 2,\n",
              " 'generic': 3,\n",
              " 'obtaining': 1,\n",
              " 'summary': 4,\n",
              " 'abstract': 2,\n",
              " 'collection': 3,\n",
              " 'documents': 2,\n",
              " 'sets': 1,\n",
              " 'images': 3,\n",
              " 'videos': 3,\n",
              " 'news': 4,\n",
              " 'stories': 1,\n",
              " 'etc': 1,\n",
              " 'second': 1,\n",
              " 'query': 4,\n",
              " 'relevant': 2,\n",
              " 'called': 2,\n",
              " 'based': 1,\n",
              " 'summarizes': 1,\n",
              " 'objects': 1,\n",
              " 'specific': 1,\n",
              " 'Summarization': 1,\n",
              " 'systems': 1,\n",
              " 'able': 1,\n",
              " 'create': 1,\n",
              " 'text': 1,\n",
              " 'summaries': 2,\n",
              " 'machine': 1,\n",
              " 'generated': 1,\n",
              " 'user': 1,\n",
              " 'needs': 1,\n",
              " '\\n': 2,\n",
              " 'example': 3,\n",
              " 'problem': 2,\n",
              " 'document': 4,\n",
              " 'attempts': 1,\n",
              " 'automatically': 3,\n",
              " 'produce': 1,\n",
              " 'given': 2,\n",
              " 'interested': 1,\n",
              " 'generating': 1,\n",
              " 'single': 1,\n",
              " 'source': 2,\n",
              " 'use': 1,\n",
              " 'multiple': 1,\n",
              " 'cluster': 1,\n",
              " 'articles': 3,\n",
              " 'topic': 2,\n",
              " 'multi': 1,\n",
              " 'related': 2,\n",
              " 'application': 2,\n",
              " 'summarizing': 1,\n",
              " 'Imagine': 1,\n",
              " 'system': 3,\n",
              " 'pulls': 1,\n",
              " 'web': 1,\n",
              " 'concisely': 1,\n",
              " 'represents': 1,\n",
              " 'latest': 1,\n",
              " 'Image': 1,\n",
              " 'automatic': 1,\n",
              " 'consists': 1,\n",
              " 'selecting': 1,\n",
              " 'representative': 2,\n",
              " 'set': 2,\n",
              " 'larger': 1,\n",
              " 'images.[4': 1,\n",
              " 'context': 1,\n",
              " 'useful': 1,\n",
              " 'results': 1,\n",
              " 'image': 1,\n",
              " 'exploration': 1,\n",
              " 'Video': 1,\n",
              " 'domain': 1,\n",
              " 'creates': 1,\n",
              " 'trailer': 1,\n",
              " 'long': 1,\n",
              " 'video': 1,\n",
              " 'applications': 1,\n",
              " 'consumer': 1,\n",
              " 'personal': 1,\n",
              " 'want': 2,\n",
              " 'skip': 1,\n",
              " 'boring': 2,\n",
              " 'repetitive': 1,\n",
              " 'actions': 1,\n",
              " 'Similarly': 1,\n",
              " 'surveillance': 1,\n",
              " 'extract': 1,\n",
              " 'important': 1,\n",
              " 'suspicious': 1,\n",
              " 'activity': 1,\n",
              " 'ignoring': 1,\n",
              " 'redundant': 1,\n",
              " 'frames': 1,\n",
              " 'captured': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDMS2B1_ANGO",
        "outputId": "3c8b248b-5f05-47c7-b75b-0a5004338c1a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itbBJ_35ANT2",
        "outputId": "62a74ebc-511d-49d9-cb4a-70a258de7e1e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'broadly': 1,\n",
              " 'types': 1,\n",
              " 'extractive': 1,\n",
              " 'summarization': 11,\n",
              " 'tasks': 1,\n",
              " 'depending': 2,\n",
              " 'program': 1,\n",
              " 'focuses': 2,\n",
              " 'generic': 3,\n",
              " 'obtaining': 1,\n",
              " 'summary': 4,\n",
              " 'abstract': 2,\n",
              " 'collection': 3,\n",
              " 'documents': 2,\n",
              " 'sets': 1,\n",
              " 'images': 3,\n",
              " 'videos': 3,\n",
              " 'news': 4,\n",
              " 'stories': 1,\n",
              " 'etc': 1,\n",
              " 'second': 1,\n",
              " 'query': 4,\n",
              " 'relevant': 2,\n",
              " 'called': 2,\n",
              " 'based': 1,\n",
              " 'summarizes': 1,\n",
              " 'objects': 1,\n",
              " 'specific': 1,\n",
              " 'Summarization': 1,\n",
              " 'systems': 1,\n",
              " 'able': 1,\n",
              " 'create': 1,\n",
              " 'text': 1,\n",
              " 'summaries': 2,\n",
              " 'machine': 1,\n",
              " 'generated': 1,\n",
              " 'user': 1,\n",
              " 'needs': 1,\n",
              " '\\n': 2,\n",
              " 'example': 3,\n",
              " 'problem': 2,\n",
              " 'document': 4,\n",
              " 'attempts': 1,\n",
              " 'automatically': 3,\n",
              " 'produce': 1,\n",
              " 'given': 2,\n",
              " 'interested': 1,\n",
              " 'generating': 1,\n",
              " 'single': 1,\n",
              " 'source': 2,\n",
              " 'use': 1,\n",
              " 'multiple': 1,\n",
              " 'cluster': 1,\n",
              " 'articles': 3,\n",
              " 'topic': 2,\n",
              " 'multi': 1,\n",
              " 'related': 2,\n",
              " 'application': 2,\n",
              " 'summarizing': 1,\n",
              " 'Imagine': 1,\n",
              " 'system': 3,\n",
              " 'pulls': 1,\n",
              " 'web': 1,\n",
              " 'concisely': 1,\n",
              " 'represents': 1,\n",
              " 'latest': 1,\n",
              " 'Image': 1,\n",
              " 'automatic': 1,\n",
              " 'consists': 1,\n",
              " 'selecting': 1,\n",
              " 'representative': 2,\n",
              " 'set': 2,\n",
              " 'larger': 1,\n",
              " 'images.[4': 1,\n",
              " 'context': 1,\n",
              " 'useful': 1,\n",
              " 'results': 1,\n",
              " 'image': 1,\n",
              " 'exploration': 1,\n",
              " 'Video': 1,\n",
              " 'domain': 1,\n",
              " 'creates': 1,\n",
              " 'trailer': 1,\n",
              " 'long': 1,\n",
              " 'video': 1,\n",
              " 'applications': 1,\n",
              " 'consumer': 1,\n",
              " 'personal': 1,\n",
              " 'want': 2,\n",
              " 'skip': 1,\n",
              " 'boring': 2,\n",
              " 'repetitive': 1,\n",
              " 'actions': 1,\n",
              " 'Similarly': 1,\n",
              " 'surveillance': 1,\n",
              " 'extract': 1,\n",
              " 'important': 1,\n",
              " 'suspicious': 1,\n",
              " 'activity': 1,\n",
              " 'ignoring': 1,\n",
              " 'redundant': 1,\n",
              " 'frames': 1,\n",
              " 'captured': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency = max(word_frequencies.values())\n",
        "max_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW6vHZzSASzc",
        "outputId": "4b48c371-dcf7-443c-8b46-cfc83cd4a3fd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to get normalized/weighted frequencies dividing all frequencies with 11\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word]/max_frequency"
      ],
      "metadata": {
        "id": "zGIcdlTzAWlp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(word_frequencies)\n",
        "word_frequencies\n",
        "#this is the normalized frequencies of each word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x77sRMZZAWsM",
        "outputId": "eeecd80f-6c94-4732-e1e2-e96eda990fea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'broadly': 0.09090909090909091,\n",
              " 'types': 0.09090909090909091,\n",
              " 'extractive': 0.09090909090909091,\n",
              " 'summarization': 1.0,\n",
              " 'tasks': 0.09090909090909091,\n",
              " 'depending': 0.18181818181818182,\n",
              " 'program': 0.09090909090909091,\n",
              " 'focuses': 0.18181818181818182,\n",
              " 'generic': 0.2727272727272727,\n",
              " 'obtaining': 0.09090909090909091,\n",
              " 'summary': 0.36363636363636365,\n",
              " 'abstract': 0.18181818181818182,\n",
              " 'collection': 0.2727272727272727,\n",
              " 'documents': 0.18181818181818182,\n",
              " 'sets': 0.09090909090909091,\n",
              " 'images': 0.2727272727272727,\n",
              " 'videos': 0.2727272727272727,\n",
              " 'news': 0.36363636363636365,\n",
              " 'stories': 0.09090909090909091,\n",
              " 'etc': 0.09090909090909091,\n",
              " 'second': 0.09090909090909091,\n",
              " 'query': 0.36363636363636365,\n",
              " 'relevant': 0.18181818181818182,\n",
              " 'called': 0.18181818181818182,\n",
              " 'based': 0.09090909090909091,\n",
              " 'summarizes': 0.09090909090909091,\n",
              " 'objects': 0.09090909090909091,\n",
              " 'specific': 0.09090909090909091,\n",
              " 'Summarization': 0.09090909090909091,\n",
              " 'systems': 0.09090909090909091,\n",
              " 'able': 0.09090909090909091,\n",
              " 'create': 0.09090909090909091,\n",
              " 'text': 0.09090909090909091,\n",
              " 'summaries': 0.18181818181818182,\n",
              " 'machine': 0.09090909090909091,\n",
              " 'generated': 0.09090909090909091,\n",
              " 'user': 0.09090909090909091,\n",
              " 'needs': 0.09090909090909091,\n",
              " '\\n': 0.18181818181818182,\n",
              " 'example': 0.2727272727272727,\n",
              " 'problem': 0.18181818181818182,\n",
              " 'document': 0.36363636363636365,\n",
              " 'attempts': 0.09090909090909091,\n",
              " 'automatically': 0.2727272727272727,\n",
              " 'produce': 0.09090909090909091,\n",
              " 'given': 0.18181818181818182,\n",
              " 'interested': 0.09090909090909091,\n",
              " 'generating': 0.09090909090909091,\n",
              " 'single': 0.09090909090909091,\n",
              " 'source': 0.18181818181818182,\n",
              " 'use': 0.09090909090909091,\n",
              " 'multiple': 0.09090909090909091,\n",
              " 'cluster': 0.09090909090909091,\n",
              " 'articles': 0.2727272727272727,\n",
              " 'topic': 0.18181818181818182,\n",
              " 'multi': 0.09090909090909091,\n",
              " 'related': 0.18181818181818182,\n",
              " 'application': 0.18181818181818182,\n",
              " 'summarizing': 0.09090909090909091,\n",
              " 'Imagine': 0.09090909090909091,\n",
              " 'system': 0.2727272727272727,\n",
              " 'pulls': 0.09090909090909091,\n",
              " 'web': 0.09090909090909091,\n",
              " 'concisely': 0.09090909090909091,\n",
              " 'represents': 0.09090909090909091,\n",
              " 'latest': 0.09090909090909091,\n",
              " 'Image': 0.09090909090909091,\n",
              " 'automatic': 0.09090909090909091,\n",
              " 'consists': 0.09090909090909091,\n",
              " 'selecting': 0.09090909090909091,\n",
              " 'representative': 0.18181818181818182,\n",
              " 'set': 0.18181818181818182,\n",
              " 'larger': 0.09090909090909091,\n",
              " 'images.[4': 0.09090909090909091,\n",
              " 'context': 0.09090909090909091,\n",
              " 'useful': 0.09090909090909091,\n",
              " 'results': 0.09090909090909091,\n",
              " 'image': 0.09090909090909091,\n",
              " 'exploration': 0.09090909090909091,\n",
              " 'Video': 0.09090909090909091,\n",
              " 'domain': 0.09090909090909091,\n",
              " 'creates': 0.09090909090909091,\n",
              " 'trailer': 0.09090909090909091,\n",
              " 'long': 0.09090909090909091,\n",
              " 'video': 0.09090909090909091,\n",
              " 'applications': 0.09090909090909091,\n",
              " 'consumer': 0.09090909090909091,\n",
              " 'personal': 0.09090909090909091,\n",
              " 'want': 0.18181818181818182,\n",
              " 'skip': 0.09090909090909091,\n",
              " 'boring': 0.18181818181818182,\n",
              " 'repetitive': 0.09090909090909091,\n",
              " 'actions': 0.09090909090909091,\n",
              " 'Similarly': 0.09090909090909091,\n",
              " 'surveillance': 0.09090909090909091,\n",
              " 'extract': 0.09090909090909091,\n",
              " 'important': 0.09090909090909091,\n",
              " 'suspicious': 0.09090909090909091,\n",
              " 'activity': 0.09090909090909091,\n",
              " 'ignoring': 0.09090909090909091,\n",
              " 'redundant': 0.09090909090909091,\n",
              " 'frames': 0.09090909090909091,\n",
              " 'captured': 0.09090909090909091}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "sentence_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5sYs0b7AW4E",
        "outputId": "e409efe6-f837-42a2-d4a6-3693564320d8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.,\n",
              " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
              " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
              " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
              " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
              " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
              " This problem is called multi-document summarization.,\n",
              " A related application is summarizing news articles.,\n",
              " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n",
              " Image collection summarization is another application example of automatic summarization.,\n",
              " It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system.,\n",
              " Video summarization is a related domain, where the system automatically creates a trailer of a long video.,\n",
              " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.,\n",
              " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cguZvNgvAoP6",
        "outputId": "230b9fed-e479-4868-b0ba-395ea4cddf32"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUxmH8DiAocG",
        "outputId": "499cbb7f-6211-4226-bc79-789239711349"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.,\n",
              " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
              " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
              " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
              " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
              " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
              " This problem is called multi-document summarization.,\n",
              " A related application is summarizing news articles.,\n",
              " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n",
              " Image collection summarization is another application example of automatic summarization.,\n",
              " It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system.,\n",
              " Video summarization is a related domain, where the system automatically creates a trailer of a long video.,\n",
              " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.,\n",
              " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the sentence score, to calculate the sentence score\n",
        "sentence_scores = {}\n",
        "\n",
        "for sent in sentence_tokens:\n",
        "    for word in sent:\n",
        "        if word.text.lower() in word_frequencies.keys():\n",
        "            if sent not in sentence_scores.keys():\n",
        "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "            else:\n",
        "                sentence_scores[sent] += word_frequencies[word.text.lower()]"
      ],
      "metadata": {
        "id": "i9NLkb-WAS5F"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8X2JxIcA1Mf",
        "outputId": "5a6bbf2b-0a58-4642-872a-06dfea1bb7ea"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
              " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
              " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
              " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.2727272727272716,\n",
              " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
              " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
              " This problem is called multi-document summarization.: 1.8181818181818183,\n",
              " A related application is summarizing news articles.: 1.0909090909090908,\n",
              " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.9090909090909087,\n",
              " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
              " It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 2.999999999999999,\n",
              " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
              " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
              " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 1.4545454545454544}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets say our case study was 30% sentence with maximum scores\n",
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "iOBLfqSwA1Wi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "select_length = int(len(sentence_tokens)*0.4)\n",
        "select_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnaD7MrYA1hu",
        "outputId": "ab726d70-0d25-4656-ddac-cb7ee01a9b2f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting maximum 4 sentences out of all sentences\n",
        "summary = nlargest(select_length,sentence_scores, key = sentence_scores.get)"
      ],
      "metadata": {
        "id": "hkLdVdccBHD4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkrVrVLyBHLU",
        "outputId": "909b172e-c359-4219-bea0-e57caaa5fa7c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
              " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
              " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
              " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
              " It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system.]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndr2sUlHA1uN",
        "outputId": "99e2556c-07eb-4bf1-c146-870280d95ad0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
              " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
              " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
              " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.2727272727272716,\n",
              " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
              " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
              " This problem is called multi-document summarization.: 1.8181818181818183,\n",
              " A related application is summarizing news articles.: 1.0909090909090908,\n",
              " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.9090909090909087,\n",
              " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
              " It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 2.999999999999999,\n",
              " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
              " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
              " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 1.4545454545454544}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if i need to combine these top 3 sentencs then\n",
        "\n",
        "final_summary = [word.text for word in summary]"
      ],
      "metadata": {
        "id": "0tg3q3hIBP7j"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7Zmd5TyBQIs",
        "outputId": "7b361e93-9893-4b6a-92fd-0489ad2b0285"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n",
              " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).',\n",
              " 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n",
              " 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n',\n",
              " 'It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system.']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the final summary of the model\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yNyWTwRBVdK",
        "outputId": "4b972b7a-58e4-4881-a6f3-855b3d29e694"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document., The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.)., The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query., Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
            ", It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system.]\n"
          ]
        }
      ]
    }
  ]
}